"""OpenAI é›†æˆæ¨¡å—

æä¾› AI å¢å¼ºåŠŸèƒ½ï¼Œä»…ä¾èµ– OpenAI APIã€‚
"""

import os
from dataclasses import dataclass
from typing import Optional, List
from openai import OpenAI


@dataclass
class AIConfig:
    """AI é…ç½®"""
    api_key: str
    model: str = "gpt-4o-mini"
    max_tokens: int = 100
    temperature: float = 0.7


class AIHandler:
    """OpenAI å¤„ç†å™¨"""

    # æç¤ºè¯æ¨¡æ¿
    PROMPT_ENHANCE = "ä¼˜åŒ–è¿™ä¸ª Todo ä»»åŠ¡æè¿°ï¼Œä¿æŒç®€æ´æœ‰åŠ›ï¼š{text}"
    PROMPT_SUGGEST = """æ ¹æ®ä»¥ä¸‹å¾…åŠä»»åŠ¡åˆ—è¡¨ï¼Œå»ºè®®ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆï¼š
{todos}

è€ƒè™‘ä¼˜å…ˆçº§ã€æ‹–å»¶æ—¶é—´å’Œä»»åŠ¡å¤æ‚åº¦ã€‚"""

    def __init__(self, config: Optional[AIConfig] = None):
        if config is None:
            config = AIConfig(
                api_key=os.getenv("OPENAI_API_KEY", ""),
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini")
            )
        if not config.api_key:
            raise ValueError("OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")

        self.config = config
        self.client = OpenAI(api_key=config.api_key)

    def enhance_input(self, text: str) -> str:
        """AI ä¼˜åŒ–ä»»åŠ¡æè¿°

        Args:
            text: åŸå§‹ä»»åŠ¡æ–‡æœ¬

        Returns:
            ä¼˜åŒ–åçš„ä»»åŠ¡æè¿°
        """
        response = self.client.chat.completions.create(
            model=self.config.model,
            messages=[
                {"role": "user", "content": self.PROMPT_ENHANCE.format(text=text)}
            ],
            max_tokens=self.config.max_tokens,
            temperature=self.config.temperature,
        )
        return response.choices[0].message.content.strip()

    def suggest_next(self, todos: List) -> str:
        """AI å»ºè®®ä¸‹ä¸€æ­¥

        Args:
            todos: ä»»åŠ¡åˆ—è¡¨

        Returns:
            å»ºè®®æ–‡æœ¬
        """
        # è¿‡æ»¤æœªå®Œæˆçš„ä»»åŠ¡
        incomplete_todos = [t for t in todos if not t.done]

        if not incomplete_todos:
            return "ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼"

        # æ ¼å¼åŒ–ä»»åŠ¡åˆ—è¡¨
        todos_text = "\n".join([
            f"- [{t.id}] {t.text} (ä¼˜å…ˆçº§: {t.priority}, {'å·²å®Œæˆ' if t.done else 'æœªå®Œæˆ'})"
            for t in incomplete_todos
        ])

        response = self.client.chat.completions.create(
            model=self.config.model,
            messages=[
                {"role": "user", "content": self.PROMPT_SUGGEST.format(todos=todos_text)}
            ],
            max_tokens=200,
            temperature=0.7,
        )
        return response.choices[0].message.content.strip()

    def chat(self, user_input: str, todos: List) -> str:
        """AI å¯¹è¯

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            todos: ä»»åŠ¡åˆ—è¡¨

        Returns:
            AI å›å¤
        """
        # æ ¼å¼åŒ–ä»»åŠ¡åˆ—è¡¨
        todos_text = "\n".join([
            f"- [{t.id}] {t.text} (ä¼˜å…ˆçº§: {t.priority})"
            for t in todos
        ])

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„ Todo åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·ç®¡ç†ä»»åŠ¡å’Œå…‹æœæ‹–å»¶ã€‚

å½“å‰ä»»åŠ¡åˆ—è¡¨ï¼š
{todos_text}

å›ç­”è¦ç®€æ´ã€æœ‰åŒç†å¿ƒã€å®ç”¨ã€‚"""

        response = self.client.chat.completions.create(
            model=self.config.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ],
            max_tokens=300,
            temperature=0.8,
        )
        return response.choices[0].message.content.strip()


def get_ai_handler() -> AIHandler:
    """è·å– AI å¤„ç†å™¨å®ä¾‹

    ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®å¹¶åˆ›å»ºå¤„ç†å™¨

    Returns:
        AIHandler å®ä¾‹

    Raises:
        ValueError: å¦‚æœç¼ºå°‘ OPENAI_API_KEY
    """
    api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        raise ValueError("OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")

    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    return AIHandler(AIConfig(api_key=api_key, model=model))
